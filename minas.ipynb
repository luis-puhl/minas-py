{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_covtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fetch_covtype in module sklearn.datasets.covtype:\n",
      "\n",
      "fetch_covtype(data_home=None, download_if_missing=True, random_state=None, shuffle=False, return_X_y=False)\n",
      "    Load the covertype dataset (classification).\n",
      "    \n",
      "    Download it if necessary.\n",
      "    \n",
      "    =================   ============\n",
      "    Classes                        7\n",
      "    Samples total             581012\n",
      "    Dimensionality                54\n",
      "    Features                     int\n",
      "    =================   ============\n",
      "    \n",
      "    Read more in the :ref:`User Guide <covtype_dataset>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data_home : string, optional\n",
      "        Specify another download and cache folder for the datasets. By default\n",
      "        all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "    \n",
      "    download_if_missing : boolean, default=True\n",
      "        If False, raise a IOError if the data is not locally available\n",
      "        instead of trying to download the data from the source site.\n",
      "    \n",
      "    random_state : int, RandomState instance or None (default)\n",
      "        Determines random number generation for dataset shuffling. Pass an int\n",
      "        for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    shuffle : bool, default=False\n",
      "        Whether to shuffle dataset.\n",
      "    \n",
      "    return_X_y : boolean, default=False.\n",
      "        If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "        object.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    dataset : dict-like object with the following attributes:\n",
      "    \n",
      "    dataset.data : numpy array of shape (581012, 54)\n",
      "        Each row corresponds to the 54 features in the dataset.\n",
      "    \n",
      "    dataset.target : numpy array of shape (581012,)\n",
      "        Each value corresponds to one of the 7 forest covertypes with values\n",
      "        ranging between 1 to 7.\n",
      "    \n",
      "    dataset.DESCR : string\n",
      "        Description of the forest covertype dataset.\n",
      "    \n",
      "    (data, target) : tuple if ``return_X_y`` is True\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "\n",
      "<class 'sklearn.utils.Bunch'>\n",
      "{'data': array([[2.596e+03, 5.100e+01, 3.000e+00, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00],\n",
      "       [2.590e+03, 5.600e+01, 2.000e+00, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00],\n",
      "       [2.804e+03, 1.390e+02, 9.000e+00, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00],\n",
      "       ...,\n",
      "       [2.386e+03, 1.590e+02, 1.700e+01, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00],\n",
      "       [2.384e+03, 1.700e+02, 1.500e+01, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00],\n",
      "       [2.383e+03, 1.650e+02, 1.300e+01, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00]]), 'target': array([5, 5, 2, ..., 3, 3, 3], dtype=int32), 'DESCR': \".. _covtype_dataset:\\n\\nForest covertypes\\n-----------------\\n\\nThe samples in this dataset correspond to 30×30m patches of forest in the US,\\ncollected for the task of predicting each patch's cover type,\\ni.e. the dominant species of tree.\\nThere are seven covertypes, making this a multiclass classification problem.\\nEach sample has 54 features, described on the\\n`dataset's homepage <http://archive.ics.uci.edu/ml/datasets/Covertype>`__.\\nSome of the features are boolean indicators,\\nwhile others are discrete or continuous measurements.\\n\\n**Data Set Characteristics:**\\n\\n    =================   ============\\n    Classes                        7\\n    Samples total             581012\\n    Dimensionality                54\\n    Features                     int\\n    =================   ============\\n\\n:func:`sklearn.datasets.fetch_covtype` will load the covertype dataset;\\nit returns a dictionary-like object\\nwith the feature matrix in the ``data`` member\\nand the target values in ``target``.\\nThe dataset will be downloaded from the web if necessary.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "help(fetch_covtype)\n",
    "dataset = fetch_covtype()\n",
    "print(type(dataset))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'label': None, 'item': [], 'timestamp': 1557118471604864000, 'tries': 0}) <class '__main__.Example'>\n",
      "Cluster({'label': 'label', 'center': [], 'n': 0, 'maxDistance': '0.00', 'lastExapleTMS': 0}) <class '__main__.Cluster'>\n",
      "Minas({'exampleCount': 0, 'knownCount': 0, 'diff': 0, 'noveltyIndex': 0, 'lastExapleTMS': 0, 'lastCleaningCycle': 0, 'clusters': [], 'sleepClusters': [], 'unknownBuffer': []}) <class '__main__.Minas'>\n"
     ]
    }
   ],
   "source": [
    "import scipy, time, os, yaml\n",
    "from timed import timed\n",
    "\n",
    "class Example:\n",
    "    __slots__ = ['label', 'item', 'timestamp', 'tries']\n",
    "    def __init__(self, item, label=None):\n",
    "        self.label = label\n",
    "        self.item = item\n",
    "        self.timestamp = time.time_ns()\n",
    "        self.tries = 0\n",
    "    def asDict(self):\n",
    "        return {'label': self.label, 'item': self.item, 'timestamp': self.timestamp, 'tries': self.tries, }\n",
    "    def __repr__(self):\n",
    "        return 'Example({!r})'.format(self.asDict())\n",
    "    def __str__(self):\n",
    "        return repr(self)\n",
    "    def __len__(self):\n",
    "        return len(self.item)\n",
    "t = Example(item=[])\n",
    "print(t, type(t))\n",
    "del t\n",
    "class Cluster:\n",
    "    __slots__ = [ 'label', 'center', 'n', 'lastExapleTMS', 'maxDistance', ]\n",
    "    def __init__(self, label, center):\n",
    "        self.label = label\n",
    "        self.center = center\n",
    "        self.n = 0\n",
    "        self.maxDistance = 0.0\n",
    "        self.lastExapleTMS = 0\n",
    "    def asDict(self):\n",
    "        return {'label': self.label, 'center': self.center, 'n': self.n, \n",
    "                'maxDistance': '{:2.2f}'.format(self.maxDistance), 'lastExapleTMS': self.lastExapleTMS,}\n",
    "    def __repr__(self):\n",
    "        return 'Cluster({!r})'.format(self.asDict())\n",
    "    def radius(self):\n",
    "        return self.maxDistance\n",
    "    def dist(self, vec):\n",
    "        return scipy.spatial.distance.euclidean(self.center, vec)\n",
    "    def __add__(self, other):\n",
    "        if type(other) == Example:\n",
    "            self.n += 1\n",
    "            self.lastExapleTMS = max(example.timestamp, self.lastExapleTMS)\n",
    "            self.maxDistance = max(self.dist(example.item), self.maxDistance)\n",
    "t = Cluster(label='label', center=[])\n",
    "print(t, type(t))\n",
    "del t\n",
    "class MinasConsts:\n",
    "    __slots__ = ['k', 'radiusFactor', 'noveltyThr', 'windowTimeSize', 'ndProcedureThr', 'representationThr', ]\n",
    "    def __init__(self):\n",
    "        self.k = 100\n",
    "        self.radiusFactor = 1.1\n",
    "        self.noveltyThr = 100\n",
    "        self.windowTimeSize = 100\n",
    "        self.ndProcedureThr = 2000\n",
    "        self.representationThr = 3\n",
    "CONSTS = MinasConsts()\n",
    "class Minas:\n",
    "    __slots__ = ['exampleCount', 'knownCount', 'noveltyIndex',\n",
    "                 'lastExapleTMS', 'lastCleaningCycle', \n",
    "                 'clusters', 'sleepClusters', 'unknownBuffer', ]\n",
    "    def __init__(self):\n",
    "        self.exampleCount = 0\n",
    "        self.knownCount = 0\n",
    "        self.noveltyIndex = 0\n",
    "        self.lastExapleTMS = 0\n",
    "        self.lastCleaningCycle = 0\n",
    "        self.clusters = []\n",
    "        self.sleepClusters = []\n",
    "        self.unknownBuffer = []\n",
    "    def asDict(self):\n",
    "        asDictMap = lambda l: [x.asDict for x in l]\n",
    "        return {\n",
    "            'exampleCount': self.exampleCount, 'knownCount': self.knownCount, 'diff': self.exampleCount - self.knownCount,\n",
    "            'noveltyIndex': self.noveltyIndex,\n",
    "            'lastExapleTMS': self.lastExapleTMS, 'lastCleaningCycle': self.lastCleaningCycle,\n",
    "            'clusters': asDictMap(self.clusters), 'sleepClusters': asDictMap(self.sleepClusters),\n",
    "            'unknownBuffer': asDictMap(self.unknownBuffer),}\n",
    "    def __repr__(self):\n",
    "        return 'Minas({!r})'.format(self.asDict())\n",
    "    def storeToFile(self, filename: str):\n",
    "        directory = os.path.dirname(filename)\n",
    "        if len(directory) > 0 and not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(yaml.dump(self.asDict()))\n",
    "        return self\n",
    "    def restoreFromFile(self, filename: str):\n",
    "        with open(filename, 'r') as f:\n",
    "            dic = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "            self.exampleCount = dic.get('exampleCount', self.exampleCount)\n",
    "            self.knownCount = dic.get('knownCount', self.knownCount)\n",
    "            self.noveltyIndex = dic.get('noveltyIndex', self.noveltyIndex)\n",
    "            self.lastExapleTMS = dic.get('lastExapleTMS', self.lastExapleTMS)\n",
    "            self.lastCleaningCycle = dic.get('lastCleaningCycle', self.lastCleaningCycle)\n",
    "            if 'clusters' in dic.keys():\n",
    "                self.clusters = [Cluster(**cl) for cl in dic['clusters']]\n",
    "            if 'sleepClusters' in dic.keys():\n",
    "                self.sleepClusters = [Cluster(**cl) for cl in dic['sleepClusters']]\n",
    "            if 'unknownBuffer' in dic.keys():\n",
    "                self.unknownBuffer = [Example(**ex) for ex in dic['unknownBuffer']]\n",
    "        return self\n",
    "    #\n",
    "    #\n",
    "    @timed\n",
    "    def clustering(self, examples, label=None):\n",
    "        kmeans = KMeans( n_clusters = min(CONSTS.k, int(len(examples) / (3 * CONSTS.representationThr))) )\n",
    "        with joblib.parallel_backend('dask'):\n",
    "            kmeans.fit(examples)\n",
    "        return [Cluster(center=centroid, label=label) for centroid in kmeans.cluster_centers_]\n",
    "    def trainGroup(self, label, group):\n",
    "        clusters = clustering(group, label)\n",
    "        for ex in group:\n",
    "            nearCl, dist = closestCluster(ex, clusters)\n",
    "            nearCl.addExample(ex)\n",
    "        return [cluster for cluster in clusters if cluster.n > CONSTS.representationThr]\n",
    "    def offline(self, examplesDf):\n",
    "        for label, group in df.groupby('label'):\n",
    "            self.clusters.append(trainGroup(label, group))\n",
    "    def classify(self, example, clusters=None):\n",
    "        example.tries += 1\n",
    "        if clusters == None:\n",
    "            clusters = self.clusters + self.sleepClusters\n",
    "        cluster, dist = closestCluster(example.item, clusters)\n",
    "        isClassified = dist <= (CONSTS.radiusFactor * cluster.radius())\n",
    "        return isClassified, cluster, dist, example\n",
    "    def online(self, stream):\n",
    "        for example in stream:\n",
    "            if example is None:\n",
    "                break\n",
    "        self.onlineProcessExample(example)\n",
    "        return self\n",
    "    @timed\n",
    "    def onlineProcessExample(self, item):\n",
    "        self.exampleCount += 1\n",
    "        example = Example(item=item)\n",
    "        self.lastExapleTMS = example.timestamp\n",
    "        isClassified, cluster, dist, example = self.classify(example, self.clusters)\n",
    "        if isClassified:\n",
    "            example.label = cluster.label\n",
    "            cluster.addExample(example)\n",
    "            self.knownCount += 1\n",
    "        else:\n",
    "            self.unknownBuffer.append(example)\n",
    "        #\n",
    "        if len(self.unknownBuffer) > CONSTS.ndProcedureThr:\n",
    "            print('bufferFull')\n",
    "            self.wakeupWithUnkownBuffer()\n",
    "            self.noveltyDetection()\n",
    "            self.cleanupCycle()\n",
    "        return example, isClassified, cluster, dist\n",
    "    @timed\n",
    "    def wakeupWithUnkownBuffer(self):\n",
    "        for sleepExample in self.unknownBuffer:\n",
    "            isClassified, cluster, dist, example = self.classify(example, self.sleepClusters)\n",
    "            if isClassified:\n",
    "                sleepExample.label = cluster.label\n",
    "                cluster.addExample(sleepExample)\n",
    "                self.unknownBuffer.remove(sleepExample)\n",
    "                # wakeup\n",
    "                print('wakeup')\n",
    "                self.clusters.append(cluster)\n",
    "                self.sleepClusters.remove(cluster)\n",
    "                self.counter += 1\n",
    "    @timed\n",
    "    def cleanupCycle(self):\n",
    "        # Model ← move-sleepMem(Model, SleepMem, CurrentTime, windowSize)\n",
    "        ogLen = len(self.clusters)\n",
    "        newClusters = []\n",
    "        for cl in self.clusters:\n",
    "            if cl.lastExapleTMS < self.lastCleaningCycle:\n",
    "                self.sleepClusters.append(cl)\n",
    "            else:\n",
    "                newClusters.append(cl)\n",
    "        self.clusters = newClusters\n",
    "        self.lastCleaningCycle = time.time_ns()\n",
    "        print(f'put to sleep {ogLen - len(newClusters)} clusters')\n",
    "        # ShortMem ← remove-oldExamples(ShortMem, windowsize)\n",
    "        ogLen = len(self.unknownBuffer)\n",
    "        self.unknownBuffer = [ex for ex in self.unknownBuffer if ex.tries >= 3]\n",
    "        print(f'removed {ogLen - len(self.unknownBuffer)} examples')\n",
    "    @timed\n",
    "    def noveltyDetection(self):\n",
    "        for cluster in clustering(self.unknownBuffer):\n",
    "            # ---------------------------------------------------------------------------------------------------\n",
    "            isRepresentative = cluster.n > CONSTS.representationThr\n",
    "            # \n",
    "            near, dist = closestCluster(cluster.center, self.clusters + self.sleepClusters)\n",
    "            distances = []\n",
    "            for ex in unknownBuffer:\n",
    "                d = cluster.dist(ex.item)\n",
    "                if d <= (CONSTS.radiusFactor * cluster.radius()):\n",
    "                    distances.append(d)\n",
    "            mean = sum(distances) / len(distances)\n",
    "            devianceSqrSum = sum((d - mean) **2 for d in distances)\n",
    "            var = devianceSqrSum / len(distances)\n",
    "            stdDevDistance = var **0.5\n",
    "            silhouette = lambda a, b: (b - a) / max([a, b])\n",
    "            # \n",
    "            isCohesive = silhouette(dist, stdDevDistance) > 0\n",
    "            validationCriterion = isRepresentative and isCohesive\n",
    "            # ---------------------------------------------------------------------------------------------------\n",
    "            if not validationCriterion:\n",
    "                continue\n",
    "            if dist <= CONSTS.noveltyThr:\n",
    "                print('Extention {}'.format(near.label))\n",
    "                cluster.label = near.label\n",
    "            else:\n",
    "                self.noveltyIndex += 1\n",
    "                label = 'Novelty {}'.format(self.noveltyIndex)\n",
    "                print(label)\n",
    "                cluster.label = label\n",
    "            self.clusters.append(cluster)\n",
    "        \n",
    "t = Minas()\n",
    "t.storeToFile('t.yaml')\n",
    "t.restoreFromFile('t.yaml')\n",
    "print(t, type(t))\n",
    "del t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function min in module builtins:\n",
      "\n",
      "min(...)\n",
      "    min(iterable, *[, default=obj, key=func]) -> value\n",
      "    min(arg1, arg2, *args, *[, key=func]) -> value\n",
      "    \n",
      "    With a single iterable argument, return its smallest item. The\n",
      "    default keyword-only argument specifies an object to return if\n",
      "    the provided iterable is empty.\n",
      "    With two or more arguments, return the smallest argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dask.datagr\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
