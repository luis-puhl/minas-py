{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def mkClass(label): return dict(label=label, mu=np.random.random_sample((2,)) * 100, sigma=np.random.random_sample((2,)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import typing\n",
    "import time\n",
    "\n",
    "Vector = typing.Union[list, np.ndarray, typing.Any, None]\n",
    "\n",
    "@dataclasses.dataclass(eq=False)\n",
    "class Example():\n",
    "    item: Vector = dataclasses.field(repr=False)\n",
    "    label: typing.Union[str, None] = None\n",
    "    timestamp: int = time.time_ns()\n",
    "    tries: int = 0\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Cluster():\n",
    "    center: Vector = dataclasses.field(repr=False)\n",
    "    latest: int = 0\n",
    "    label: typing.Union[str, None] = None\n",
    "    n: int = 0\n",
    "    maxDist: float = 0.0\n",
    "    temp_examples=[]\n",
    "    timestamp: int = time.time_ns()\n",
    "    def __eq__(self, other):\n",
    "        return self.timestamp == other.timestamp\n",
    "    def __hash__(self):\n",
    "        return self.timestamp\n",
    "\n",
    "def nextExample(klass): return Example(label=klass['label'], item=np.random.normal(klass['mu'], klass['sigma']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(map(mkClass, ['zero', 'one', 'duo', 'tri']))\n",
    "list(map(nextExample, classes))\n",
    "def nextRandExample(classes=classes): return nextExample(np.random.choice(classes) )\n",
    "def randExamplesIter(classes=classes):\n",
    "    while True:\n",
    "        yield nextRandExample(classes=classes)\n",
    "def loopExamplesIter(classes=classes):\n",
    "    i = 0\n",
    "    while True:\n",
    "        msg = yield nextExample(classes[i])\n",
    "        if not msg is None:\n",
    "            classes = msg\n",
    "        i = (i + 1) % len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402.32578237182986,\n",
       " {'label': 'tri',\n",
       "  'mu': array([ 4.51208994, 41.23035739]),\n",
       "  'sigma': array([38.08822701, 17.09195495])})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distKlass(ex, classes=classes): return map(lambda cl: (sum((cl['mu'] - ex.item) ** 2) ** 1/2, cl), classes)\n",
    "def minDistKlass(ex, classes=classes): return min(distKlass(ex, classes), key=lambda x: x[0])\n",
    "minDistKlass(nextExample(classes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNKNOWN] 0: [15.64996149 18.1785631 ]',\n",
       " '[UNKNOWN] 1: [38.38132693 13.58680306]',\n",
       " '[UNKNOWN] 2: [-24.20412078  71.91300488]',\n",
       " '[UNKNOWN] 3: [74.96243014 19.30642532]',\n",
       " '[UNKNOWN] 4: [39.04617806 41.73840594]',\n",
       " '[CLASSIFIED] 5: one',\n",
       " '[UNKNOWN] 6: [-71.7627684  107.65412462]',\n",
       " '[CLASSIFIED] 7: tri',\n",
       " '[UNKNOWN] 8: [-77.47662986 -47.70570014]',\n",
       " '[UNKNOWN] 9: [108.26825192  13.66088017]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = [ Cluster(center=cl['mu'], label=cl['label'], n=0, maxDist=sum(cl['sigma']), latest=0) for cl in classes ]\n",
    "unkBuff = []\n",
    "outStream = []\n",
    "inStream = zip(range(10), loopExamplesIter())\n",
    "\n",
    "def dist(ex, clusters=clusters): return map(lambda cl: (sum((cl.center - ex.item) ** 2) ** 1/2, cl), clusters)\n",
    "def minDist(ex, clusters=clusters): return min(dist(ex, clusters), key=lambda x: x[0])\n",
    "for i, example in inStream:\n",
    "    d, cl = minDist(example)\n",
    "    if d / cl.maxDist <= 1.1:\n",
    "        outStream.append(f'[CLASSIFIED] {i}: {cl.label}')\n",
    "        cl.maxDist = max(cl.maxDist, d)\n",
    "    else:\n",
    "        outStream.append(f'[UNKNOWN] {i}: {example.item}')\n",
    "        unkBuff.append(example)\n",
    "outStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minasOnline(exampleSource, inClusters=[]):\n",
    "    RADIUS_FACTOR = 1.1\n",
    "    BUFF_FULL = 100\n",
    "    MAX_K_CLUSTERS = 100\n",
    "    REPR_TRESHOLD = 20\n",
    "    CLEANUP_WINDOW = 100\n",
    "    #\n",
    "    unknownBuffer = []\n",
    "    clusters=[cl for cl in inClusters]\n",
    "    sleepClusters = []\n",
    "    counter = 0\n",
    "    noveltyIndex = 0\n",
    "    sentinel = object()\n",
    "    while True:\n",
    "        example = next(exampleSource, sentinel)\n",
    "        if example is sentinel:\n",
    "            yield 'done'\n",
    "            return\n",
    "        example = Example(item=example.item)\n",
    "        counter += 1\n",
    "        example.timestamp = time.time_ns()\n",
    "        example.n = counter\n",
    "        dists = map(lambda cl: (sum((cl.center - example.item) ** 2) ** 1/2, cl), clusters)\n",
    "        d, cl = min(dists, key=lambda x: x[0])\n",
    "        if d / cl.maxDist <= RADIUS_FACTOR:\n",
    "            cl.maxDist = max(cl.maxDist, d)\n",
    "            cl.latest = counter\n",
    "            cl.n += 1\n",
    "            yield f\"[CLASSIFIED] {example.n}: {cl.label}\"\n",
    "        else:\n",
    "            unknownBuffer.append(example)\n",
    "            yield f\"[UNKNOWN] {example.n}: {example.item}\"\n",
    "            if len(unknownBuffer) > BUFF_FULL:\n",
    "                if len(sleepClusters) > 0:\n",
    "                    yield f'[recurenceDetection] unk={len(unknownBuffer)}, sleep={len(sleepClusters)}'\n",
    "                    # recurenceDetection\n",
    "                    for sleepExample in unknownBuffer:\n",
    "                        sleepDists = list(map(lambda cl: (sum((cl.center - sleepExample.item) ** 2) ** 1/2, cl), sleepClusters))\n",
    "                        if len(sleepDists) == 0: continue\n",
    "                        d, cl = min(sleepDists, key=lambda x: x[0])\n",
    "                        if d / cl.maxDist <= 1.1:\n",
    "                            cl.maxDist = max(cl.maxDist, d)\n",
    "                            cl.latest = counter\n",
    "                            unknownBuffer.remove(sleepExample)\n",
    "                            yield f\"[CLASSIFIED] {sleepExample.n}: {cl.label}\"\n",
    "                            if cl in sleepClusters:\n",
    "                                clusters.append(cl)\n",
    "                                sleepClusters.remove(cl)\n",
    "                                yield f\"[Recurence] {cl.label}\"\n",
    "                if len(unknownBuffer) % (BUFF_FULL // 10) == 0:\n",
    "                    yield '[noveltyDetection]'\n",
    "                    # noveltyDetection\n",
    "                    df = pd.DataFrame([ex.item for ex in unknownBuffer])\n",
    "                    n_clusters = min(MAX_K_CLUSTERS, len(unknownBuffer) // ( 3 * REPR_TRESHOLD))\n",
    "                    kmeans = KMeans(n_clusters=n_clusters)\n",
    "                    kmeans.fit(df)\n",
    "                    newClusters = [Cluster(center=centroid, label=None, n=0, maxDist=0, latest=0) for centroid in kmeans.cluster_centers_]\n",
    "                    temp_examples = {cl: [] for cl in newClusters}\n",
    "                    for sleepExample in unknownBuffer:\n",
    "                        dists = map(lambda cl: (sum((cl.center - sleepExample.item) ** 2) ** 1/2, cl), newClusters)\n",
    "                        d, cl = min(dists, key=lambda x: x[0])\n",
    "                        cl.maxDist = max(cl.maxDist, d)\n",
    "                        cl.latest = counter\n",
    "                        cl.n += 1\n",
    "                        temp_examples[cl].append((sleepExample, d))\n",
    "                    for ncl in newClusters:\n",
    "                        if ncl.n < 2: continue\n",
    "                        distances = [ d for ex, d in temp_examples[ncl] ]\n",
    "                        if len(distances) == 0: continue\n",
    "                        distsCl2Cl = map(lambda cl: (sum((cl.center - ncl.center) ** 2) ** 1/2, cl), clusters + sleepClusters)\n",
    "                        distCl2Cl, nearCl2Cl = min(distsCl2Cl, key=lambda x: x[0])\n",
    "                        #\n",
    "                        mean = sum(distances) / len(distances)\n",
    "                        devianceSqrSum = sum([(d - mean) **2 for d in distances])\n",
    "                        var = devianceSqrSum / len(distances)\n",
    "                        stdDevDistance = var **0.5\n",
    "                        silhouetteFn = lambda a, b: (b - a) / max([a, b])\n",
    "                        silhouette = silhouetteFn(stdDevDistance, distCl2Cl)\n",
    "                        if silhouette < 0: continue\n",
    "                        # \n",
    "                        if distCl2Cl / nearCl2Cl.maxDist < 10:\n",
    "                            yield f'Extention {nearCl2Cl.label}'\n",
    "                            ncl.label = nearCl2Cl.label\n",
    "                        else:\n",
    "                            label = 'Novelty {}'.format(noveltyIndex)\n",
    "                            ncl.label = label\n",
    "                            yield label\n",
    "                            noveltyIndex += 1\n",
    "                        clusters.append(ncl)\n",
    "                        for ex, d in temp_examples[ncl]:\n",
    "                            if ex in unknownBuffer:\n",
    "                                yield f\"[CLASSIFIED] {ex.n}: {ncl.label}\"\n",
    "                                unknownBuffer.remove(ex)\n",
    "        if counter % CLEANUP_WINDOW == 0:\n",
    "            yield '[cleanup]'\n",
    "            for ex in unknownBuffer:\n",
    "                if counter - ex.n < 3 * CLEANUP_WINDOW:\n",
    "                    unknownBuffer.remove(ex)\n",
    "            for cl in clusters:\n",
    "                if counter - cl.latest < 2 * CLEANUP_WINDOW:\n",
    "                    sleepClusters.append(cl)\n",
    "                    clusters.remove(cl)\n",
    "            if len(clusters) == 0:\n",
    "                yield f'[fallback] {len(sleepClusters)} => clusters'\n",
    "                # fallback \n",
    "                clusters.extend(sleepClusters)\n",
    "                sleepClusters.clear()\n",
    "            #\n",
    "        #\n",
    "    #\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metaMinas(minasMaping):\n",
    "    status = dict(\n",
    "        known = 0,\n",
    "        unknown = 0,\n",
    "        cleanup = 0,\n",
    "        fallback = 0,\n",
    "        recurenceDetection = 0,\n",
    "        recurence = 0,\n",
    "        noveltyDetection = 0,\n",
    "    )\n",
    "    sentinel = object()\n",
    "    while minasMaping:\n",
    "        o = next(minasMaping, sentinel)\n",
    "        if o == sentinel:\n",
    "            break\n",
    "        if '[CLASSIFIED]' in o:\n",
    "            status['known'] += 1\n",
    "        elif '[UNKNOWN]' in o:\n",
    "            status['unknown'] += 1\n",
    "        elif '[cleanup]' in o:\n",
    "            status['cleanup'] += 1\n",
    "        elif '[fallback]' in o:\n",
    "            status['fallback'] += 1\n",
    "        elif '[recurenceDetection]' in o:\n",
    "            status['recurenceDetection'] += 1\n",
    "        elif '[noveltyDetection]' in o:\n",
    "            status['noveltyDetection'] += 1\n",
    "        elif '[Recurence]' in o:\n",
    "            status['recurence'] += 1\n",
    "        else: \n",
    "            yield o\n",
    "    else:\n",
    "        yield 'Stream Done'\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Recurence] zero\n",
      "Novelty 0\n",
      "Novelty 1\n",
      "Extention Novelty 0\n",
      "Novelty 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-17d17e33441e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minputStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloopExamplesIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetaMinas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminasOnline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputStream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnewClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmkClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'New {kl}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-d3b56768231d>\u001b[0m in \u001b[0;36mmetaMinas\u001b[0;34m(minasMaping)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mminasMaping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminasMaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-f383054e4077>\u001b[0m in \u001b[0;36mminasOnline\u001b[0;34m(exampleSource, inClusters)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexampleSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m'done'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-cc100b7054c5>\u001b[0m in \u001b[0;36mloopExamplesIter\u001b[0;34m(classes)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mnextExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ebe21ba2f25c>\u001b[0m in \u001b[0;36mnextExample\u001b[0;34m(klass)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mnextExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sigma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/project/minas-py/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36many\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m     \"\"\"\n\u001b[0;32m-> 2164\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'any'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/minas-py/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classes = list(map(mkClass, ['zero', 'one', 'duo', 'tri']))\n",
    "clusters = [ Cluster(center=cl['mu'], label=cl['label'], n=0, maxDist=sum(cl['sigma']), latest=0) for cl in classes ]\n",
    "    \n",
    "inputStream = loopExamplesIter()\n",
    "for kl in range(10):\n",
    "    for i, o in zip(range(10), metaMinas(minasOnline(inputStream, clusters))):\n",
    "        print(o)\n",
    "    newClass = mkClass(f'New {kl}')\n",
    "    print(newClass)\n",
    "    classes.append(newClass)\n",
    "    inputStream.send(classes)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "{'known': 22501, 'unknown': 832, 'cleanup': 232, 'fallback': 31, 'recurenceDetection': 3, 'recurence': 94, 'noveltyDetection': 1}\n",
      "done\n",
      "{'known': 22217, 'unknown': 1244, 'cleanup': 232, 'fallback': 30, 'recurenceDetection': 6, 'recurence': 222, 'noveltyDetection': 0}\n",
      "Extention 6\n",
      "Extention 2\n",
      "done\n",
      "{'known': 21997, 'unknown': 1698, 'cleanup': 232, 'fallback': 23, 'recurenceDetection': 37, 'recurence': 256, 'noveltyDetection': 4}\n",
      "done\n",
      "{'known': 22364, 'unknown': 1150, 'cleanup': 232, 'fallback': 30, 'recurenceDetection': 10, 'recurence': 275, 'noveltyDetection': 1}\n",
      "Extention 5\n",
      "done\n",
      "{'known': 22102, 'unknown': 1576, 'cleanup': 232, 'fallback': 28, 'recurenceDetection': 58, 'recurence': 329, 'noveltyDetection': 2}\n",
      "done\n",
      "{'known': 22554, 'unknown': 799, 'cleanup': 232, 'fallback': 31, 'recurenceDetection': 3, 'recurence': 114, 'noveltyDetection': 1}\n",
      "done\n",
      "{'known': 22403, 'unknown': 1026, 'cleanup': 232, 'fallback': 30, 'recurenceDetection': 5, 'recurence': 190, 'noveltyDetection': 1}\n",
      "done\n",
      "{'known': 22217, 'unknown': 1234, 'cleanup': 232, 'fallback': 30, 'recurenceDetection': 12, 'recurence': 212, 'noveltyDetection': 1}\n",
      "17.9 s ± 2.58 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "from sklearn.datasets import fetch_covtype\n",
    "dataset = fetch_covtype()\n",
    "total = len(dataset.data)\n",
    "zipToMap = lambda x: {'item': x[0], 'label': str(x[1])}\n",
    "onePercent = int(total*0.01)\n",
    "baseMap = map(zipToMap, zip(dataset.data[:onePercent], dataset.target[:onePercent]))\n",
    "onPercentDataFrame = pd.DataFrame(baseMap)\n",
    "\n",
    "# def minasOffline(examplesDf):\n",
    "RADIUS_FACTOR = 1.1\n",
    "BUFF_FULL = 100\n",
    "MAX_K_CLUSTERS = 100\n",
    "REPR_TRESHOLD = 20\n",
    "#\n",
    "clusters = []\n",
    "groupSize = MAX_K_CLUSTERS * REPR_TRESHOLD\n",
    "for label, group in examplesDf.groupby('label'):\n",
    "    for chunk in range(0, len(group), groupSize):\n",
    "        subgroup = group[chunk:chunk + groupSize]\n",
    "        unknownBuffer = list(subgroup['item'])\n",
    "        df = pd.DataFrame(unknownBuffer)\n",
    "        n_clusters = min(MAX_K_CLUSTERS, len(unknownBuffer) // ( 3 * REPR_TRESHOLD))\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        kmeans.fit(df)\n",
    "        newClusters = [Cluster(center=centroid, label=label, n=0, maxDist=0, latest=0) for centroid in kmeans.cluster_centers_]\n",
    "        temp_examples = {cl: [] for cl in newClusters}\n",
    "        for sleepExample in unknownBuffer:\n",
    "            dists = map(lambda cl: (sum((cl.center - sleepExample) ** 2) ** 1/2, cl), newClusters)\n",
    "            d, cl = min(dists, key=lambda x: x[0])\n",
    "            cl.maxDist = max(cl.maxDist, d)\n",
    "            cl.n += 1\n",
    "            temp_examples[cl].append((sleepExample, d))\n",
    "        for ncl in newClusters:\n",
    "            if ncl.n < 2: continue\n",
    "            #\n",
    "            clusters.append(ncl)\n",
    "# return clusters\n",
    "# clusters = minasOffline(onPercentDataFrame)\n",
    "fivePercent = int(total*0.05)\n",
    "fivePercentZip = zip(dataset.data[onePercent+1:fivePercent], map(str, dataset.target[onePercent+1:fivePercent]))\n",
    "# fivePercentDataIterator = list(fivePercentZip)\n",
    "inputStream = ( Example(item=i[0], label=i[1]) for i in fivePercentZip)\n",
    "for o in metaMinas(minasOnline(inputStream, clusters)):\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
